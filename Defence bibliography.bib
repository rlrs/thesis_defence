
@article{bareinboimPearlHierarchyFoundations,
  title = {1 {{On Pearl}}’s {{Hierarchy}} and the {{Foundations}} of {{Causal Inference}}},
  author = {Bareinboim, Elias and Correa, Juan D and Ibeling, Duligur and Icard, Thomas},
  pages = {62},
  langid = {english},
  file = {/Users/Rasmus/Zotero/storage/PBDW9MU5/Bareinboim et al. - 1 On Pearl’s Hierarchy and the Foundations of Caus.pdf}
}

@article{herlauReinforcementLearningCausal,
  title = {Reinforcement {{Learning}} of {{Causal Variables}} Using {{Mediation Analysis}}},
  author = {Herlau, Tue and Larsen, Rasmus},
  pages = {8},
  abstract = {We consider the problem of acquiring causal representations and concepts in a reinforcement learning setting. Our approach defines a causal variable as being both manipulable by a policy, and able to predict the outcome. We thereby obtain a parsimonious causal graph in which interventions occur at the level of policies. The approach avoids defining a generative model of the data, prior pre-processing, or learning the transition kernel of the Markov decision process. Instead, causal variables and policies are determined by maximizing a new optimization target inspired by mediation analysis, which differs from the expected return. The maximization is accomplished using a generalization of Bellman’s equation which is shown to converge, and the method finds meaningful causal representations in a simulated environment.},
  langid = {english},
  file = {/Users/Rasmus/Zotero/storage/SUJ8ZA9Y/Herlau and Larsen - Reinforcement Learning of Causal Variables using M.pdf}
}

@article{hoValueAbstraction2019,
  title = {The Value of Abstraction},
  author = {Ho, Mark K and Abel, David and Griffiths, Thomas L and Littman, Michael L},
  date = {2019-10-01},
  journaltitle = {Current Opinion in Behavioral Sciences},
  shortjournal = {Current Opinion in Behavioral Sciences},
  series = {Artificial {{Intelligence}}},
  volume = {29},
  pages = {111--116},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2019.05.001},
  abstract = {In neuroscience, attention has been shown to bidirectionally interact with reinforcement learning (RL) to reduce the dimensionality of task representations, restricting computations to relevant features. In machine learning, despite their popularity, attention mechanisms have seldom been administered to decision-making problems. Here, we leverage a theoretical model from computational neuroscience – the attention-weighted RL (AWRL), defining how humans identify task-relevant features (i.e., that allow value predictions) – to design an applied deep RL paradigm. We formally demonstrate that the conjunction of the self-attention mechanism, widely employed in machine learning, with value function approximation is a general formulation of the AWRL model. To evaluate our agent, we train it on three Atari tasks at different complexity levels, incorporating both task-relevant and irrelevant features. Because the model uses semantic observations, we can uncover not only which features the agent elects to base decisions on, but also how it chooses to compile more complex, relational features from simpler ones. We first show that performance depends in large part on the ability to compile new compound features, rather than mere focus on individual features. In line with neuroscience predictions, self-attention leads to high resiliency to noise (irrelevant features) compared to other benchmark models. Finally, we highlight the importance and separate contributions of both bottom-up and top-down attention in the learning process. Together, these results demonstrate the broader validity of the AWRL framework in complex task scenarios, and illustrate the benefits of a deeper integration between neuroscience-derived models and RL for decision making in machine learning.},
  langid = {english},
  file = {/Users/Rasmus/Zotero/storage/LBBBNK2T/Ho et al. - 2019 - The value of abstraction.pdf;/Users/Rasmus/Zotero/storage/AT7FB2Y9/S2352154619300026.html}
}

@inproceedings{larsenProgrammaticPolicyExtraction2022,
  title = {Programmatic {{Policy Extraction}} by {{Iterative Local Search}}},
  booktitle = {Inductive {{Logic Programming}}},
  author = {Larsen, Rasmus and Schmidt, Mikkel Nørgaard},
  editor = {Katzouris, Nikos and Artikis, Alexander},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {156--166},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-030-97454-1_11},
  abstract = {Reinforcement learning policies are often represented by neural networks, but programmatic policies are preferred in some cases because they are more interpretable, amenable to formal verification, or generalize better. While efficient algorithms for learning neural policies exist, learning programmatic policies is challenging. Combining imitation-projection and dataset aggregation with a local search heuristic, we present a simple and direct approach to extracting a programmatic policy from a pretrained neural policy. After examining our local search heuristic on a programming by example problem, we demonstrate our programmatic policy extraction method on a pendulum swing-up problem. Both when trained using a hand crafted expert policy and a learned neural policy, our method discovers simple and interpretable policies that perform almost as well as the original.},
  isbn = {978-3-030-97454-1},
  langid = {english},
  keywords = {Hindley-Milner type system,Neighborhood search,Program synthesis,Reinforcement learning},
  file = {/Users/Rasmus/Zotero/storage/EK238PHC/Larsen and Schmidt - 2022 - Programmatic Policy Extraction by Iterative Local .pdf}
}

@book{pearlBookWhyNew2018,
  title = {The {{Book}} of {{Why}}: {{The New Science}} of {{Cause}} and {{Effect}}},
  shorttitle = {The {{Book}} of {{Why}}},
  author = {Pearl, Judea and Mackenzie, Dana},
  date = {2018-05-15},
  publisher = {{Hachette UK}},
  abstract = {A Turing Award-winning computer scientist and statistician shows how understanding causality has revolutionized science and will revolutionize artificial intelligence "Correlation is not causation." This mantra, chanted by scientists for more than a century, has led to a virtual prohibition on causal talk. Today, that taboo is dead. The causal revolution, instigated by Judea Pearl and his colleagues, has cut through a century of confusion and established causality -- the study of cause and effect -- on a firm scientific basis. His work explains how we can know easy things, like whether it was rain or a sprinkler that made a sidewalk wet; and how to answer hard questions, like whether a drug cured an illness. Pearl's work enables us to know not just whether one thing causes another: it lets us explore the world that is and the worlds that could have been. It shows us the essence of human thought and key to artificial intelligence. Anyone who wants to understand either needs The Book of Why.},
  isbn = {978-0-465-09761-6},
  langid = {english},
  pagetotal = {423},
  keywords = {Business & Economics / Statistics,Computers / Artificial Intelligence / General,Computers / Computer Science,Mathematics / Probability & Statistics / General,Science / Applied Sciences}
}

@book{pearlCausality2009a,
  title = {Causality},
  author = {Pearl, Judea},
  date = {2009-09-14},
  publisher = {{Cambridge University Press}},
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. The book will open the way for including causal analysis in the standard curricula of statistics, artificial intelligence, business, epidemiology, social sciences, and economics. Students in these fields will find natural models, simple inferential procedures, and precise mathematical definitions of causal concepts that traditional texts have evaded or made unduly complicated. The first edition of Causality has led to a paradigmatic change in the way that causality is treated in statistics, philosophy, computer science, social science, and economics. Cited in more than 5,000 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interests to students and professionals in a wide variety of fields. Anyone who wishes to elucidate meaningful relationships from data, predict effects of actions and policies, assess explanations of reported events, or form theories of causal understanding and causal speech will find this book stimulating and invaluable.},
  isbn = {978-0-521-89560-6},
  langid = {english},
  pagetotal = {487},
  keywords = {Computers / Artificial Intelligence / General,Mathematics / History & Philosophy,Philosophy / Epistemology,Philosophy / Movements / Analytic,Science / Philosophy & Social Aspects,Social Science / Research}
}

@inproceedings{pearlDirectIndirectEffects2001,
  title = {Direct and Indirect Effects},
  booktitle = {Proceedings of the {{Seventeenth}} Conference on {{Uncertainty}} in Artificial Intelligence},
  author = {Pearl, Judea},
  date = {2001-08-02},
  series = {{{UAI}}'01},
  pages = {411--420},
  publisher = {{Morgan Kaufmann Publishers Inc.}},
  location = {{San Francisco, CA, USA}},
  abstract = {The direct effect of one event on another can be defined and measured by holding constant all intermediate variables between the two. Indirect effects present conceptual and practical difficulties (in nonlinear models), because they cannot be isolated by holding certain variables constant. This paper presents a new way of defining the effect transmitted through a restricted set of paths, without controlling variables on the remaining paths. This permits the assessment of a more natural type of direct and indirect effects, one that is applicable in both linear and nonlinear models and that has broader policy-related interpretations. The paper establishes conditions under which such assessments can be estimated consistently from experimental and nonexperimental data, and thus extends path-analytic techniques to nonlinear and nonparametric models.},
  isbn = {978-1-55860-800-9},
  file = {/Users/Rasmus/Zotero/storage/LSCQ5JW6/Pearl - 2001 - Direct and indirect effects.pdf}
}


